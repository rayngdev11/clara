# # CUDA_VISIBLE_DEVICES=0 python gradio_app.py
# #!/bin/bash

# export CUDA_VISIBLE_DEVICES=0

export TMPDIR=/home/clara/tmp
mkdir -p /home/clara/tmp
# Ki·ªÉm tra n·∫øu ng∆∞·ªùi d√πng kh√¥ng truy·ªÅn GPU ID v√†o
if [ -z "$1" ]; then
    echo "‚ùå Vui l√≤ng truy·ªÅn s·ªë GPU v√†o. V√≠ d·ª•: ./app.sh 1 ho·∫∑c ./app.sh 0,1"
    exit 1
fi

# GPU ID do ng∆∞·ªùi d√πng nh·∫≠p
GPU_IDS=$1

# Ch·∫°y Gradio app v·ªõi GPU ƒë∆∞·ª£c ch·ªçn
CUDA_VISIBLE_DEVICES=$GPU_IDS python gradio_app.py

# CUDA_VISIBLE_DEVICES=0 python gradio_app.py
#!/bin/bash

# export TMPDIR=/home/datnvt/tmp
# mkdir -p "$TMPDIR"

# # Ki·ªÉm tra GPU ID
# if [ -z "$1" ]; then
#     echo "‚ùå Vui l√≤ng truy·ªÅn s·ªë GPU v√†o. V√≠ d·ª•: ./app.sh 1 ho·∫∑c ./app.sh 0,1"
#     exit 1
# fi

# GPU_IDS=$1

# # Clear PyTorch CUDA cache tr∆∞·ªõc khi ch·∫°y app
# echo "üßπ Clearing PyTorch CUDA cache..."
# python -c "
# import torch
# if torch.cuda.is_available():
#     torch.cuda.empty_cache()
#     torch.cuda.reset_peak_memory_stats()
# print('‚úÖ Cache cleared')
# "

# # T√πy ch·ªçn: n√¢ng gi·ªõi h·∫°n s·ªë l∆∞·ª£ng file m·ªü (n·∫øu l·ªói li√™n quan ƒë·∫øn `.so`)
# ulimit -n 65535

# # T√πy ch·ªçn: preload th∆∞ vi·ªán n·∫øu c·∫ßn
# # export LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libcuda.so

# # Ch·∫°y Gradio app
# echo "üöÄ Running Gradio app on GPU $GPU_IDS"
# CUDA_VISIBLE_DEVICES=$GPU_IDS python gradio_app.py
